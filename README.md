# üöÄ Projeto de Pipeline End-to-End: Previs√£o de Churn com Databricks e MLOps

Este reposit√≥rio cont√©m o c√≥digo de um projeto de portf√≥lio que demonstra um pipeline completo de Engenharia de Dados e Machine Learning (MLOps) na plataforma Databricks, utilizando o Unity Catalog.

**Objetivo:** Prever a probabilidade de *churn* (cancelamento) de clientes de uma empresa de telecomunica√ß√µes, construindo um pipeline que vai desde a ingest√£o dos dados brutos at√© a "produ√ß√£o" de um modelo de IA.

---

## üõ†Ô∏è Ferramentas e Conceitos Aplicados

* **Plataforma:** Databricks (com Unity Catalog)
* **Processamento de Dados:** Apache Spark (PySpark)
* **Armazenamento (Lakehouse):** Delta Lake
* **MLOps (Ciclo de Vida de ML):** MLflow (Tracking e Model Registry)
* **Modelagem (IA):** Scikit-learn (Logistic Regression, Random Forest)
* **Linguagem:** Python

---

## üèóÔ∏è Arquitetura do Pipeline

O projeto √© executado em um √∫nico notebook Databricks (`churn_pipeline.py`) e √© dividido em tr√™s fases distintas que simulam um ambiente de produ√ß√£o real:

### Fase 1: Engenharia de Dados (ETL com Arquitetura Bronze/Silver)

O objetivo desta fase √© pegar dados brutos e "sujos" e transform√°-los em um *produto de dados* limpo, confi√°vel e pronto para an√°lise.

1.  **Camada Bronze:** Os dados s√£o lidos de um arquivo CSV bruto (`WA_Fn-UseC_-Telco-Customer-Churn.csv`) e carregados em um DataFrame Spark.
2.  **Camada Prata:** O DataFrame passa por um processo de limpeza e transforma√ß√£o:
    * Tratamento de valores nulos (ex: `TotalCharges` com " " -> 0).
    * Padroniza√ß√£o dos nomes das colunas (ex: `customerID` -> `id_cliente`).
    * Remo√ß√£o de colunas irrelevantes (`id_cliente`).
3.  **Entrega:** O DataFrame limpo (`df_prata`) √© salvo em formato **Delta Lake** (`/Volumes/workspace/default/up/churn_prata`), servindo como a fonte √∫nica da verdade (Single Source of Truth) para a pr√≥xima fase.

### Fase 2: Ci√™ncia de Dados e MLOps

Com os dados limpos, o "chap√©u" de Cientista de Dados √© assumido para treinar e gerenciar os modelos de IA.

1.  **Carregamento de Features:** Os dados s√£o lidos da tabela Delta `churn_prata`.
2.  **Pr√©-processamento:** √â criado um `ColumnTransformer` (`preprocessor`) do Scikit-learn para converter dados categ√≥ricos (One-Hot Encoding) e normalizar dados num√©ricos (Standard Scaler).
3.  **Rastreamento de Experimentos (MLflow):**
    * O `mlflow.sklearn.autolog()` √© ativado para rastrear automaticamente m√©tricas e par√¢metros.
    * Dois modelos s√£o treinados dentro de "runs" do MLflow para compara√ß√£o:
        * `Baseline_RegressaoLogistica_v2` (Modelo Simples)
        * `Challenger_RandomForest_v2` (Modelo Complexo)
    * **Crucial:** O artefato `preprocessor` √© salvo manualmente (`mlflow.sklearn.log_model(preprocessor, "preprocessor")`) junto com o modelo, garantindo que o pipeline de infer√™ncia possa replicar as transforma√ß√µes.
4.  **Registro de Modelos (MLOps):** O melhor modelo (`Challenger_RandomForest_v2`) √© registrado no **Unity Catalog** com o nome de 3 partes: `workspace.default.modelo_churn`.

### Fase 3: Infer√™ncia em Lote (Simula√ß√£o de Produ√ß√£o)

Esta fase simula um *job* agendado que usa o modelo em produ√ß√£o para gerar previs√µes.

1.  **Carregamento de Artefatos:** O pipeline carrega os artefatos diretamente do MLflow, garantindo que a vers√£o correta seja usada:
    * O `preprocessor` √© carregado pelo seu `run_id`.
    * O modelo de IA √© carregado pelo seu nome e vers√£o registrados: `models:/workspace.default.modelo_churn/1`.
2.  **Gera√ß√£o de Previs√µes:** O modelo √© usado para prever o *churn* em dados de teste (simulando novos dados).
3.  **Camada Ouro:** As previs√µes (`churn_previsto`) s√£o unidas aos dados originais e salvas em uma tabela Delta final (`/Volumes/workspace/default/up/churn_predicoes`). Esta tabela "Ouro" √© o produto final, pronto para ser consumido por um dashboard de BI ou analista.

---

## üìà Resultados

#### Rastreamento de Experimentos no MLflow
https://github.com/AbnerRidigolo/databricks-churn-pipeline-mlflow/issues/1#issue-3583457449

#### Tabela de Previs√µes Finais (Camada Ouro)
![Image](https://github.com/user-attachments/assets/c32e86cd-ad62-473f-8faf-15056745248f)

---

## üöÄ Como Executar o Projeto

1.  **Setup:** Crie uma conta de Free Trial no Databricks.
2.  **Upload do CSV:** Baixe o dataset "Telco Customer Churn" do Kaggle. Fa√ßa o upload do arquivo CSV para um Volume no Databricks (ex: `/Volumes/workspace/default/up/`).
3.  **Criar Notebook:** Crie um novo notebook e anexe-o a um cluster.
4.  **Importar C√≥digo:** Importe o arquivo `churn_pipeline.py` para o notebook (ou copie e cole o c√≥digo).
5.  **Atualizar Caminhos:**
    * **C√©lula 1:** Atualize `caminho_csv` para o local onde voc√™ salvou o CSV.
    * **C√©lula 3:** Atualize `caminho_delta` para onde voc√™ deseja salvar a tabela Prata.
6.  **Executar C√©lulas 1-7:** Rode as c√©lulas em ordem.
7.  **Atualizar C√©lula 8:** Ap√≥s rodar a C√©lula 7, v√° na UI do MLflow, copie o **"Run ID"** do experimento `Challenger_RandomForest_v2` e cole-o na vari√°vel `run_id` da C√©lula 8.
8.  **Registrar Modelo:** Siga os passos na C√©lula 7 (coment√°rios) para registrar o modelo no Unity Catalog com o nome `workspace.default.modelo_churn`.
9.  **Executar C√©lula 8:** Execute a c√©lula final para gerar as previs√µes.
